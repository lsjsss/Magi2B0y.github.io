<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>机器学习--KNN算法</title>
      <link href="/2022/06/30/Machine_Learning--KNN_algorithm/"/>
      <url>/2022/06/30/Machine_Learning--KNN_algorithm/</url>
      
        <content type="html"><![CDATA[<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;}</style><h2 id="1-概述">1. 概述</h2><p>KNN算法可以说是最简单的分类算法之一，同时，它也是最常用的分类算法之一，该算法是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例，这K个实例的多数属于某个类，就把该输入实例分类到这个类中，类似于现实生活中少数服从多数的思想。</p><p>下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。</p><div class="center"><img src="/2022/06/30/Machine_Learning--KNN_algorithm/1-1.png" height="300" width="330"></div><h2 id="2-算法流程">2. 算法流程</h2><p>在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：</p><ul><li>计算已知类别数据集中的点与当前点之间的距离</li><li>按距离递增次序排序</li><li>选取与当前点距离最小的k个点</li><li>统计前k个点所在的类别出现的频率</li><li>返回前k个点出现频率最高的类别作为当前点的预测分类</li></ul><p><strong>KNN取距离度量的方式:</strong></p><p><strong>距离计算：</strong></p><p>要度量空间中点距离的话，有好几种度量方式，比如常见的曼哈顿距离计算，欧式距离计算等等。不过通常KNN算法中使用的是欧式距离，这里只是简单说一下，拿二维平面为例，，二维空间两个点的欧式距离计算公式如下：</p><div class="center"><img src="/2022/06/30/Machine_Learning--KNN_algorithm/2-1.png"></div><p>拓展到多维空间，则公式变成这样：</p><div class="center"><img src="/2022/06/30/Machine_Learning--KNN_algorithm/2-2.png"></div><p>KNN算法最简单粗暴的就是将预测点与所有点距离进行计算，然后保存并排序，选出前面K个值看看哪些类别比较多。</p><p><strong>K值选择：</strong></p><p>在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。</p><ul><li><p>如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；</p></li><li><p>如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。</p></li><li><p>K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</p></li></ul><h2 id="3-KNN算法的特点与优缺点">3. KNN算法的特点与优缺点</h2><h3 id="3-1-特点">3.1 特点</h3><p>KNN是一种非参的，惰性的算法模型。</p><ul><li><p><strong>非参：</strong> 模型不会对数据做出任何的假设，与之相对的是线性回归（我们总会假设线性回归是一条直线）。也就是说KNN建立的模型结构是根据数据来决定的。</p></li><li><p><strong>惰性：</strong> 同样是分类算法，逻辑回归需要先对数据进行大量训练，最后才会得到一个算法模型。而KNN算法却不需要，它没有明确的训练数据的过程，或者说这个过程很快。</p></li></ul><h3 id="3-2-KNN算法的优势和劣势">3.2 KNN算法的优势和劣势</h3><p><strong>优点：</strong></p><ul><li>KNN算法简洁明了，模型训练时间快</li><li>预测效果好，对异常值不敏感</li></ul><p><strong>缺点：</strong></p><ul><li>对内存要求较高，因为该算法存储了所有训练数据</li><li>预测阶段可能很慢</li><li>对不相关的功能和数据规模敏感</li></ul><h2 id="4-KNN算法的应用">4. KNN算法的应用</h2><p>在实现为用户推荐相似好友、生成每首歌的相似音乐和为用户提供推荐音乐三个功能上应用到了KNN算法</p><p><strong>数据源：</strong> 数据库中所有用户的听歌记录</p><p><strong>数据结果：</strong> 为所有用户生成相似好友，为每首歌生成相似歌曲，最后根据每首歌的相似歌曲和用户听歌记录来为用户提供推荐音乐</p><p>项目文件功能如下表：</p><div class="center"><table><thead><tr><th>文件名</th><th>功能</th></tr></thead><tbody><tr><td>main_function.py</td><td>顺序执行以下py文件</td></tr><tr><td>update_data_source.py</td><td>读取数据库中需要的数据，作为模型训练的数据集，存储在dataset下</td></tr><tr><td>other_user_recommend.py</td><td>训练得到所有用户的相似用户</td></tr><tr><td>user_listened_recommend.py</td><td>将训练得到的相似音乐和用户听歌记录相结合，得到所有用户的音乐推荐</td></tr><tr><td>insert_DB.py</td><td>将结果集重新存入数据库</td></tr></tbody></table></div><p>python文件的调用流程如下：</p><div class="center"><img src="/2022/06/30/Machine_Learning--KNN_algorithm/4-1.png"></div><br>关键的模型训练部分代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_trainset_algo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    KNN算法使用训练集进行训练</span></span><br><span class="line"><span class="string">    :return:训练结果</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    reader = Reader(line_format=<span class="string">&#x27;user item rating timestamp&#x27;</span>, sep=<span class="string">&#x27;\t&#x27;</span>,  rating_scale=(<span class="number">0</span>, <span class="number">100</span>),skip_lines=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 用户听歌记录文件路径</span></span><br><span class="line">    file_path = <span class="string">&quot;./dataset/user_record.txt&quot;</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    data = Dataset.load_from_file(file_path, reader=reader)</span><br><span class="line">    <span class="comment"># 将数据集转换成矩阵形式</span></span><br><span class="line">    trainset = data.build_full_trainset()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(trainset.all_items())</span><br><span class="line">    <span class="built_in">print</span>(trainset.all_users())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基于物品的协同过滤算法，相似度衡量方法：皮尔逊相似度</span></span><br><span class="line">    <span class="comment"># 这是一个用户数量N，矩阵大小为 N*N 的稀疏矩阵，然后get_neighbors得到的是topK个相似用户。如果想要得到相似歌曲，则需要使用基于项目的协同过滤算法，</span></span><br><span class="line">    <span class="comment"># 或者从得到的相似用户中，提取他们的播放记录（这是基于用户的协同过滤算法）</span></span><br><span class="line">    sim_options = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;pearson_baseline&#x27;</span>, <span class="string">&#x27;user_based&#x27;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">    <span class="comment"># 选择KNN算法</span></span><br><span class="line">    algo = KNNBaseline(sim_options=sim_options)</span><br><span class="line">    <span class="comment"># algo = KNNBasic(sim_options=sim_options)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练数据集</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始训练······&#x27;</span>)</span><br><span class="line">    algo.fit(trainset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;训练结束!!!!&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> algo</span><br></pre></td></tr></table></figure><p><strong>输出结果集：</strong></p><p>每首音乐的10首相似音乐：</p><div class="center"><img src="/2022/06/30/Machine_Learning--KNN_algorithm/4-4.png"></div><p>为每位用户推荐的20首音乐：</p><div class="center"><img src="/2022/06/30/Machine_Learning--KNN_algorithm/4-2.png"></div><p>为每位用户推荐的10位相似好友：</p><div class="center"><img src="/2022/06/30/Machine_Learning--KNN_algorithm/4-3.png"></div><hr><p>ENDฅฅ</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/04/08/hello-world/"/>
      <url>/2022/04/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to my Blog! This is my very first post.</p><p>my blog is based on <a href="https://hexo.io/">Hexo</a></p><p>Check: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a> for more info.</p><p>If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask the author on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start">Quick Start</h2><h3 id="Create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server-at-localhost">Run server at localhost</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Clear-the-cache-file-and-the-generated-static-file">Clear the cache file and the generated static file</h3><p>When the website shows an exception, you can try this command</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure><h3 id="Generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><hr><p><strong>END</strong></p>]]></content>
      
      
      <categories>
          
          <category> Welcome，欢迎 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Welcome </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
